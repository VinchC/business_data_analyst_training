# (a) Commen√ßons par la phase d'importation des packages. Importer les packages pandas et numpy sous leur alias usuels.
import pandas as pd
import numpy as np

# (b) Ex√©cuter la cellule suivante pour stocker la liste des d√©lais r√©pertori√©es pour 20 livraisons.
# l'√©chantillon : 
delais = [40, 39, 46, 40, 42, 46, 38, 50, 43, 62, 51, 41, 52, 40, 49, 55, 50, 48, 40, 49]

# (c) √âcrire les hypoth√®ses du test.
# H0 : mu = 45 <=> le temps moyen reste inchang√©, donc √©gal √† 45
# H1 : mu > 45 <=> le temps moyen a chang√©, donc sup√©rieur √† 45

# (d) Stocker le seuil de 5% dans une variable alpha.
alpha = 0.05

# (e) En utilisant numpy, coder une fonction S(echantillon, mu0) qui permet de calculer la statistique de test en fonction de l'√©chantillon donn√© et de la moyenne th√©orique. Appliquer le param√®tre ddof=1 √† la m√©thode std de numpy qui retourne l'√©cart type corrig√©.
# La formule de la statistique de test : 
def S(echantillon, mu0):
    # 3 variables avec : moyenne observ√©e + √©cart-type observ√© + taille de l'√©chantillon 
    mu_obs = np.mean(echantillon)
    std_obs = np.std(echantillon, ddof=1)
    n = len(echantillon)
    
    # formule de la statistique du test :
    S = (mu_obs-mu0)/(std_obs/np.sqrt(n))
    return S

# (f) Cr√©er une variable S_obs en appliquant cette fonction sur l'√©chantillon donn√© et avec la valeur de la moyenne th√©orique.
# Calcul de la statistique de test sur l'√©chantillon delais :
S_obs = S(delais, 45)
print("La valeur de S_obs est: ", S_obs)

# (g) Importer la librairie scipy.stats qui contient un grand nombre de statistiques de test et de distributions de probabilit√©s.
# Pour utiliser la loi de Student nous importons t de scipy.stats.
# Dans la fonction t.cdf() il faut pr√©ciser le quantile, sp√©cifi√© dans le param√®tre x , et le nombre de degr√©s de libert√©s, sp√©cifi√© dans le param√®tre df(degree of freedom).
# Importation des librairies et fonctions n√©cessaires :
import scipy.stats as stats
from scipy.stats import t

# Calcul de la p-valeur
p_val = 1 - t.cdf(x = S_obs, df = len(delais) - 1) # x = le quantile / df = degree of freedom
print("La p-valeur est √©gale √† :", p_val)

# (i) Interpr√©ter le r√©sultat de la  p-valeur obtenue afin de d√©terminer si le nouveau syst√®me de traitement a eu un effet significatif sur le d√©lai de livraison des commandes. Conclure.
print("p-valeur = ", p_val, "// alpha = ", alpha)
# pval ~ 0.23 > 0.05, on ne rejette pas H_0. 
# par cons√©quent on ne peut pas conclure √† une augmentation de temps de d√©lai suite au nouveau syst√®me de traitement mis en place dans le magasin.
# on note qu'avec un test statistique on ne peut pas dire de combien √ßa a augment√©/diminu√© - on peut juste tester les deux hypoth√®ses

# (j) Importer la fonction ttest_1samp puis r√©aliser le test de Student pour l'√©chantillon donn√© et retrouver les valeurs (la statistique du test et la p-valeur) que nous avons calcul√© auparavant "√† la main".
from scipy.stats import ttest_1samp

## t-test :  
t_test = ttest_1samp(a = delais, popmean = 45, alternative='greater')

print("statistic: ", t_test[0], ", p-value: ", t_test[1])
# on remarque que les valeurs sont quasiment les m√™mes que celles calcul√©es √† la main,
# cependant elles diff√®rent parfois car selon le contexte il peut y avoir des corrections ajout√©es aux tests.

# (k) Charger dans un dataframe nomm√© df les donn√©es situ√©es dans le fichier 'heart.csv' et afficher les 5 premi√®res lignes.
df = pd.read_csv("heart.csv")
df.head()

# (l) √âcrire les hypoth√®ses et r√©aliser un test de Pearson pour tester la corr√©lation entre la variable tension et √¢ge.
# (m) Conclure.
## Les hypoth√®ses :
# H0 : Les variables tension et √¢ge ne sont pas corr√©l√©es
# H1 : Les deux variables sont corr√©l√©es 

## Le test : 
from scipy.stats import pearsonr
pearsonr(x = df["tension"], y = df["age"]) 

print("p-value: ", pearsonr(x = df["tension"], y = df["age"])[1])
print("coefficient: ", pearsonr(x = df["tension"], y = df["age"])[0])

# la p-valeur est tr√®s petite < 0.05, on rejette H0 et on conclut H1 c'est-√†-dire qu'il y a une corr√©lation entre les variables tension et √¢ge. 
# une p-valeur < Œ±, indique une corr√©lation statistiquement significatitive entre les variables x et y. Le coefficient nous permet de voir l'intensit√© de la corr√©lation.

# (n) Cr√©er deux √©chantillons : x = une liste de valeurs enti√®res de 1 √† 20 et y = l'exponentielle du carr√© de ces valeurs (en utilisant la librairie numpy).
# (o) Importer la fonction spearmanr de la librairie scipy.stats et r√©aliser un test de correlation entre les variables x et y.
# (p) R√©aliser √©galement un test de Pearson.
# (q) Conclure.
## Cr√©ation des √©chantillons
x = np.arange(1,21)
y = np.exp(x**2) 

## Pearson vs. Spearman
# importation de la fonction : 
from scipy.stats import spearmanr
s = spearmanr(x, y)[1] # p-valeur du test spearmanr
p = pearsonr(x,y)[1] # p-valeur du test pearsonr
print("Pearson :", p, "//", "Spearman : ", s)

## Conclusion :
# Avec la p-valeur du test de Spearman on conclut √† une corr√©lation et effectivement il y a une corr√©lation entre x et y car y a √©t√© cr√©e √† partir de x. 
# Cependant la p-valeur de Pearson ne d√©tecte pas cette corr√©lation car elle n'est pas de nature lin√©aire.

# (r) Quelles sont les modalit√©s de la colonne "douleur_thor"?
# (s) Nous voulons savoir s'il y a un lien entre le type de la douleur thoracique et la fr√©quence cardiaque maximale. Pour cela, posons d'abord les hypoth√®ses pour r√©aliser un test d'ANOVA.
## Les modalit√©s de douleur_thor :
print("Les diff√©rentes modalit√©s sont :", df["douleur_thor"].unique())

## Les hypoth√®ses :
print("Les hypoth√®ses : ")
print("H0 : Il n'y a pas d'influence significative du type de la douleur sur la fr√©quence maximale")
print("H1 : Il y a une influence significative du type de la douleur sur la fr√©quence maximale")

# (t) Pour r√©aliser un test ANOVA nous utilisons la m√©thode suivante :
#  Le test ANOVA :
import statsmodels.api 
result = statsmodels.formula.api.ols('freq_card_max ~ douleur_thor', data=df).fit()
table = statsmodels.api.stats.anova_lm(result)
display(table)

# La conclusion :
print("Conclusion : La p-value (PR(>F)) est inf√©rieure √† 5% donc on rejette H0 et on conclut H1")
# On conclut donc √† une influence significative du type de la douleur sur la fr√©quence maximale

# (u) Y a-t-il une influence du type de la douleur thoracique sur la tension? √âcrire les hypoth√®ses, appliquer le test d'ANOVA et conclure.
## 1 - Les hypoth√®ses :
# H0 : Il n'y a pas d'influence du type de la douleur sur la tension
# H1 : Il y a une influence significative du type de la douleur sur la tension

# 2 - le test statistique adapt√©, ici ANOVA :
result2 = statsmodels.formula.api.ols('tension ~ douleur_thor', data=df).fit()
table2 = statsmodels.api.stats.anova_lm(result2)
table2

# 3 - Conclusion : 
# p-val > 5% 
# on ne peut pas conclure √† une influence significative de la variable douleur thoracique sur la tension.


# (v) Pour faire un test de ùúí2, nous devons passer par une √©tape interm√©diaire qui permet de r√©aliser une table de contingence entre la variable sex et la variable douleur_thor. Cette table permet de compter les occurrences selon les deux variables qualitatives.
# Pour r√©aliser une table de contingence nous pouvons utiliser la fonction crosstab de pandas.
ct = pd.crosstab(df['douleur_thor'], df['sex'])
ct

# Explication sur la table de contingence : 
# dans le dataframe df on a 70 femmes avec la modalit√© ASY pour la variable douleur_thor on a √©galement 150 hommes avec la modalit√© NAP etc.

# (w) Nous remarquons que le type ASY est pr√©sent chez de nombreux hommes. Pouvons-nous dire que les hommes ont plus tendance √† avoir le type ASY?
ct = pd.crosstab(df['douleur_thor'], df['sex'])
ct

# Explication sur la table de contingence : 
# dans le dataframe df on a 36% de femmes avec la modalit√© ASY pour la variable douleur_thor
# on a √©galement 20% hommes avec la modalit√© NAP etc.

# (x) Poser les hypoth√®ses du test statistique qui permet de r√©pondre √† cette probl√©matique.
# (y) Importer la fonction chi2_contingency du module scipy.stats. Cette fonction prend en argument un tableau de contingence et r√©alise le test de ùúí2 pour les deux variables qualitatives. Comme pour le test de corr√©lation, le r√©sultat retourn√© est un tuple : la premi√®re valeur est la statistique du test et la deuxi√®me est la p-valeur. R√©aliser le test et conclure.
## Hypoth√®ses : 
# ùêª0 : La variable douleur thoracique est ind√©pendante du sexe de l'individu
# H1 : La variable douleur thoracique n'est pas ind√©pendante du sexe

## Le test chi2 d'ind√©pendance : 
from scipy.stats import chi2_contingency
resultats_chi2 = chi2_contingency(ct)

statistique = resultats_chi2[0]
p_valeur = resultats_chi2[1]
print("La statistique du test est : ", statistique, "\n"
      "La p-valeur du test est : ", p_valeur, "\n")


# Conclusions : 
print("Conclusion : p-val tr√®s petite (< 0.05) => on rejette H0 et on accepte H1.")
# on conclut √† une d√©pendance entre le sex et le type de douleur thoracique
# le test n'en dit pas plus sur la d√©pendance, il v√©rifie seulement son existence.